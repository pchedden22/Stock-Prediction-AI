{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75fd0983-3eec-4026-bc9f-33b8b6858976",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ta import add_all_ta_features\n",
    "from ta.utils import dropna\n",
    "\n",
    "class StockDataHandler:\n",
    "    def __init__(self, tickers, api_key, outputsize=\"full\", cache_dir=\"cached_data\"):\n",
    "        self.tickers = tickers\n",
    "        self.api_key = api_key\n",
    "        self.outputsize = outputsize  # Get long-term data\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(cache_dir, exist_ok=True)\n",
    "        self.data = {}\n",
    "\n",
    "    def fetch_data(self):\n",
    "        \"\"\"Fetch and cache 10 years of stock data.\"\"\"\n",
    "        base_url = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            cache_file = os.path.join(self.cache_dir, f\"{ticker}.csv\")\n",
    "\n",
    "            # ‚úÖ Check cache first\n",
    "            if os.path.exists(cache_file):\n",
    "                print(f\"üìÇ Loading cached data for {ticker}...\")\n",
    "                df = pd.read_csv(cache_file, index_col=0, parse_dates=True)\n",
    "                self.data[ticker] = df\n",
    "                continue\n",
    "\n",
    "            print(f\"üåê Fetching 10 years of data for {ticker} from API...\")\n",
    "            params = {\n",
    "                \"function\": \"TIME_SERIES_DAILY\",\n",
    "                \"symbol\": ticker,\n",
    "                \"outputsize\": self.outputsize,  # \"full\" gets 20+ years\n",
    "                \"datatype\": \"json\",\n",
    "                \"apikey\": self.api_key\n",
    "            }\n",
    "\n",
    "            response = requests.get(base_url, params=params)\n",
    "            data = response.json()\n",
    "\n",
    "            if \"Time Series (Daily)\" not in data:\n",
    "                print(f\"‚ùå Error fetching {ticker}: {data.get('Note', 'No data available.')}\")\n",
    "                continue\n",
    "\n",
    "            # ‚úÖ Convert API Response to DataFrame\n",
    "            df = pd.DataFrame.from_dict(data[\"Time Series (Daily)\"], orient=\"index\")\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df = df.sort_index()\n",
    "\n",
    "            print(f\"üöÄ Raw Columns for {ticker}: {df.columns.tolist()}\")  # Debugging output BEFORE renaming\n",
    "\n",
    "\n",
    "            # ‚úÖ **Rename columns properly**\n",
    "            df = df.rename(columns={\n",
    "                \"1. open\": \"open\", \n",
    "                \"2. high\": \"high\",\n",
    "                \"3. low\": \"low\", \n",
    "                \"4. close\": \"close\",  # ‚úÖ Correcting the key error\n",
    "                \"5. volume\": \"volume\"\n",
    "            }).astype(float)\n",
    "\n",
    "            print(f\"üìä Columns in {ticker}: {df.columns.tolist()}\")  # Debugging output\n",
    "\n",
    "\n",
    "            # ‚úÖ Keep Only the Last **10 Years**\n",
    "            ten_years_ago = pd.Timestamp.today() - pd.DateOffset(years=10)\n",
    "            df = df[df.index >= ten_years_ago]\n",
    "\n",
    "            # ‚úÖ Add Technical Indicators\n",
    "            df = dropna(df)\n",
    "            df = add_all_ta_features(df, open=\"open\", high=\"high\", low=\"low\", close=\"close\", volume=\"volume\")\n",
    "\n",
    "            # ‚úÖ Save to Cache\n",
    "            df.to_csv(cache_file)\n",
    "            self.data[ticker] = df\n",
    "\n",
    "            # üïí **Avoid hitting API limit**\n",
    "            time.sleep(12)\n",
    "\n",
    "    def get_data(self):\n",
    "        \"\"\"Return stock data as a pandas DataFrame.\"\"\"\n",
    "        if not self.data:\n",
    "            raise ValueError(\"No valid stock data found. Check API key and ticker symbols.\")\n",
    "        \n",
    "        # üîç Debugging: Print column names to check structure\n",
    "        for ticker, df in self.data.items():\n",
    "            print(f\"üîç Checking {ticker} columns: {df.columns.tolist()}\")\n",
    "    \n",
    "        # ‚úÖ Flatten MultiIndex if necessary (for some versions of pandas)\n",
    "        for ticker in self.data:\n",
    "            if isinstance(self.data[ticker].columns, pd.MultiIndex):\n",
    "                print(f\"üîß Flattening MultiIndex for {ticker}\")\n",
    "                self.data[ticker].columns = self.data[ticker].columns.droplevel(0)\n",
    "    \n",
    "        # ‚úÖ Ensure correct column names\n",
    "        for ticker in self.data:\n",
    "            if \"4. close\" in self.data[ticker].columns:\n",
    "                print(f\"üîß Fixing column name for {ticker}\")\n",
    "                self.data[ticker] = self.data[ticker].rename(columns={\"4. close\": \"close\"})\n",
    "        \n",
    "        # ‚úÖ Convert data dictionary into a DataFrame\n",
    "        df = pd.concat(self.data, axis=1)\n",
    "    \n",
    "        # ‚úÖ Handle missing values\n",
    "        df.dropna(how=\"all\", inplace=True)  # Drop rows where all tickers have NaN\n",
    "        \n",
    "        if df.empty:\n",
    "            raise ValueError(\"Stock data is empty after processing. Check cache or API response.\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e07aa5d-3573-4144-806e-88cce1044e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class XGBoostTrader:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"Initialize with stock data.\"\"\"\n",
    "        self.df = df\n",
    "        self.tickers = [col.split(\"_\")[0] for col in df.columns]  # ‚úÖ Extract tickers\n",
    "        self.models = {}\n",
    "\n",
    "    def prepare_data(self, stock_df):\n",
    "        \"\"\"Prepare features and target for XGBoost.\"\"\"\n",
    "        df = stock_df.copy()\n",
    "        \n",
    "        # ‚úÖ Ensure we use the correct column name\n",
    "        close_col = df.columns[0]  # Should be like 'AAPL_close'\n",
    "        \n",
    "        # ‚úÖ Generate features (e.g., simple moving averages)\n",
    "        df[\"SMA_10\"] = df[close_col].rolling(window=10).mean()\n",
    "        df[\"SMA_50\"] = df[close_col].rolling(window=50).mean()\n",
    "        df[\"SMA_200\"] = df[close_col].rolling(window=200).mean()\n",
    "        \n",
    "        # ‚úÖ Target: 1 if price increases next day, else 0\n",
    "        df[\"target\"] = (df[close_col].shift(-1) > df[close_col]).astype(int)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # ‚úÖ Split into training and test sets\n",
    "        X = df.drop(columns=[close_col, \"target\"])\n",
    "        y = df[\"target\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def train_models(self):\n",
    "        \"\"\"Train XGBoost models for each stock.\"\"\"\n",
    "        self.models = {}\n",
    "\n",
    "        for ticker in self.tickers:\n",
    "            column_name = f\"{ticker}_close\"\n",
    "            \n",
    "            if column_name not in self.df.columns:\n",
    "                print(f\"‚ùå Skipping {ticker}: Column {column_name} not found.\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"üöÄ Training XGBoost for {ticker}...\")\n",
    "            stock_df = self.df[[column_name]]  # ‚úÖ Use only the correct column\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = self.prepare_data(stock_df)\n",
    "            model = xgb.XGBClassifier(eval_metric=\"logloss\")\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            self.models[ticker] = model\n",
    "\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(f\"üìà Accuracy for {ticker}: {accuracy:.4f}\")\n",
    "\n",
    "    def predict(self, df):\n",
    "        predictions = {}\n",
    "    \n",
    "        # ‚úÖ Ensure we keep a full DataFrame, not separate per-stock DataFrames\n",
    "        stock_df = df.copy()\n",
    "    \n",
    "        for ticker in self.tickers:\n",
    "            feature_columns = [f\"{ticker}_SMA_10\", f\"{ticker}_SMA_50\", f\"{ticker}_SMA_200\"]\n",
    "    \n",
    "            close_col = f\"{ticker}_close\"\n",
    "            if close_col not in stock_df.columns:\n",
    "                print(f\"‚ùå Warning: Missing {close_col} in DataFrame. Skipping {ticker}.\")\n",
    "                continue\n",
    "    \n",
    "            # ‚úÖ Generate missing features if needed\n",
    "            if not all(col in stock_df.columns for col in feature_columns):\n",
    "                print(f\"üîß Generating missing features for {ticker}...\")\n",
    "                stock_df.loc[:, f\"{ticker}_SMA_10\"] = stock_df[close_col].rolling(window=10).mean()\n",
    "                stock_df.loc[:, f\"{ticker}_SMA_50\"] = stock_df[close_col].rolling(window=50).mean()\n",
    "                stock_df.loc[:, f\"{ticker}_SMA_200\"] = stock_df[close_col].rolling(window=200).mean()\n",
    "                stock_df.dropna(inplace=True)  # ‚úÖ Remove NaN values\n",
    "    \n",
    "            feature_columns = [col for col in feature_columns if col in stock_df.columns]  # ‚úÖ Validate feature presence\n",
    "            if len(feature_columns) < 3:\n",
    "                print(f\"‚ùå Warning: Not enough features for {ticker} (Expected 3, Found {len(feature_columns)}). Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            if ticker not in self.models:\n",
    "                print(f\"‚ùå Warning: Model for {ticker} not found. Skipping.\")\n",
    "                continue\n",
    "    \n",
    "            # ‚úÖ Use the last row for prediction\n",
    "            X = stock_df[feature_columns].tail(1).values.reshape(1, -1)\n",
    "    \n",
    "            print(f\"üîç Predicting for {ticker}, Feature Shape: {X.shape}\")  # Debug print\n",
    "    \n",
    "            predictions[ticker] = self.models[ticker].predict(X)[0]\n",
    "    \n",
    "        return pd.DataFrame(predictions, index=[stock_df.index[-1]])  # ‚úÖ Convert to DataFrame for consistency\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe7cfc36-14bc-4f33-94e0-cf2d1ec2dcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gym import spaces\n",
    "\n",
    "class StockTradingEnv(gym.Env):\n",
    "    def __init__(self, tickers, stock_data, xgb_trader, initial_cash=10000):\n",
    "        super(StockTradingEnv, self).__init__()\n",
    "        self.tickers = tickers\n",
    "        self.df = stock_data if isinstance(stock_data, pd.DataFrame) else pd.concat(stock_data.values(), axis=1, keys=stock_data.keys())\n",
    "        self.initial_cash = initial_cash\n",
    "        self.cash = initial_cash\n",
    "        self.shares = {ticker: 0 for ticker in self.tickers}\n",
    "        self.current_step = 0\n",
    "        self.xgb_trader = xgb_trader  # ‚úÖ Ensure trader is properly passed in\n",
    "\n",
    "        # ‚úÖ FIX: Use MultiDiscrete instead of Box\n",
    "        self.action_space = spaces.MultiDiscrete(np.array([3] * len(self.tickers), dtype=np.int32))\n",
    "\n",
    "\n",
    "        # ‚úÖ Print for debugging\n",
    "        print(f\"‚úÖ Action Space: {self.action_space}\")\n",
    "\n",
    "        # ‚úÖ Ensure observation space is properly formatted\n",
    "        num_features = len(self.df.columns) + 1 + len(self.tickers)  # Prices, technical indicators + cash + holdings\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(num_features,), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Resets the environment.\"\"\"\n",
    "        self.cash = self.initial_cash\n",
    "        self.shares = {ticker: 0 for ticker in self.tickers}\n",
    "        self.current_step = 0\n",
    "        return self._get_obs(), {}  # ‚úÖ Return observation & info dict\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"‚úÖ Execute an action in the environment.\"\"\"\n",
    "        if self.current_step >= len(self.df) - 1:\n",
    "            return self._get_obs(), 0, True, {}\n",
    "    \n",
    "        prices = self.df.iloc[self.current_step]\n",
    "    \n",
    "        for i, ticker in enumerate(self.tickers):\n",
    "            action_value = action[i]\n",
    "    \n",
    "            if action_value == 1 and self.cash >= prices[ticker]:  # Buy\n",
    "                self.shares[ticker] += 1\n",
    "                self.cash -= prices[ticker]\n",
    "            elif action_value == 2 and self.shares[ticker] > 0:  # Sell\n",
    "                self.shares[ticker] -= 1\n",
    "                self.cash += prices[ticker]\n",
    "            # Hold (0) does nothing\n",
    "    \n",
    "        # ‚úÖ Advance to the next step\n",
    "        self.current_step += 1\n",
    "        done = self.current_step >= len(self.df) - 1\n",
    "    \n",
    "        # ‚úÖ Calculate reward based on portfolio value\n",
    "        portfolio_value = self.cash + sum(self.shares[t] * prices[t] for t in self.tickers)\n",
    "        reward = portfolio_value - self.initial_cash  # Reward = Profit Change\n",
    "    \n",
    "        return self._get_obs(), reward, done, {}\n",
    "\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"‚úÖ Get the current state as a flat observation array.\"\"\"\n",
    "        prices = self.df.iloc[self.current_step].values.flatten().astype(np.float32)\n",
    "        holdings = np.array([self.shares[t] for t in self.tickers], dtype=np.float32)\n",
    "    \n",
    "        # ‚úÖ Ensure cash is a 1D array\n",
    "        cash_array = np.array([self.cash], dtype=np.float32)\n",
    "    \n",
    "        obs = np.concatenate((cash_array, prices, holdings), axis=0)\n",
    "    \n",
    "        # ‚úÖ Ensure `xgb_predictions` are properly formatted\n",
    "        if self.xgb_trader is not None:\n",
    "            xgb_predictions = np.array(\n",
    "                [self.xgb_trader[ticker] if ticker in self.xgb_trader else 0 for ticker in self.tickers],\n",
    "                dtype=np.float32\n",
    "            ).flatten()\n",
    "    \n",
    "            obs = np.concatenate((obs, xgb_predictions), axis=0)\n",
    "    \n",
    "        # ‚úÖ Convert explicitly to a NumPy array with shape (n_features,)\n",
    "        obs = np.asarray(obs, dtype=np.float32).reshape(1, -1).squeeze()\n",
    "    \n",
    "        # ‚úÖ Debug output\n",
    "        print(f\"üîç Final obs.shape: {obs.shape}, obs.dtype: {obs.dtype}, type(obs): {type(obs)}\")\n",
    "    \n",
    "        return obs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        \"\"\"Sets the seed for reproducibility.\"\"\"\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    def render(self):\n",
    "        \"\"\"Prints the portfolio and cash state.\"\"\"\n",
    "        portfolio_value = self.cash + sum(self.shares[t] * self.df.iloc[self.current_step][t] for t in self.tickers)\n",
    "\n",
    "        print(f\"Step: {self.current_step}\")\n",
    "        print(f\"Cash: ${self.cash:.2f}\")\n",
    "        print(\"Holdings:\", {t: self.shares[t] for t in self.tickers})\n",
    "        print(f\"Total Portfolio Value: ${portfolio_value:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797ac3b8-9d65-455b-bb42-3f686d285240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading cached data for AAPL...\n",
      "üìÇ Loading cached data for GOOGL...\n",
      "üìÇ Loading cached data for MSFT...\n",
      "üìÇ Loading cached data for TSLA...\n",
      "üîç Checking AAPL columns: ['4. close']\n",
      "üîç Checking GOOGL columns: ['4. close']\n",
      "üîç Checking MSFT columns: ['4. close']\n",
      "üîç Checking TSLA columns: ['4. close']\n",
      "üîß Fixing column name for AAPL\n",
      "üîß Fixing column name for GOOGL\n",
      "üîß Fixing column name for MSFT\n",
      "üîß Fixing column name for TSLA\n",
      "üìä Updated DataFrame Columns: Index(['AAPL_close', 'GOOGL_close', 'MSFT_close', 'TSLA_close'], dtype='object')\n",
      "üöÄ Training XGBoost for AAPL...\n",
      "üìà Accuracy for AAPL: 0.5140\n",
      "üöÄ Training XGBoost for GOOGL...\n",
      "üìà Accuracy for GOOGL: 0.4320\n",
      "üöÄ Training XGBoost for MSFT...\n",
      "üìà Accuracy for MSFT: 0.4687\n",
      "üöÄ Training XGBoost for TSLA...\n",
      "üìà Accuracy for TSLA: 0.5119\n",
      "üìä DataFrame Columns Before Prediction: Index(['AAPL_close', 'GOOGL_close', 'MSFT_close', 'TSLA_close'], dtype='object')\n",
      "‚úÖ Action Space: MultiDiscrete([3 3 3 3])\n",
      "Using cpu device\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "The algorithm only supports (<class 'gymnasium.spaces.box.Box'>, <class 'gymnasium.spaces.discrete.Discrete'>, <class 'gymnasium.spaces.multi_discrete.MultiDiscrete'>, <class 'gymnasium.spaces.multi_binary.MultiBinary'>) as action spaces but MultiDiscrete([3 3 3 3]) was provided",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 42\u001b[0m\n\u001b[0;32m     38\u001b[0m     xgb_predictions \u001b[38;5;241m=\u001b[39m {ticker: \u001b[38;5;28mfloat\u001b[39m(np\u001b[38;5;241m.\u001b[39marray(prediction)\u001b[38;5;241m.\u001b[39mflatten()[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m ticker, prediction \u001b[38;5;129;01min\u001b[39;00m xgb_predictions\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     41\u001b[0m env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: StockTradingEnv(tickers, df, xgb_predictions)])\n\u001b[1;32m---> 42\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     43\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20000\u001b[39m)\n\u001b[0;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstock_trading_ppo_xgb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:109\u001b[0m, in \u001b[0;36mPPO.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, batch_size, n_epochs, gamma, gae_lambda, clip_range, clip_range_vf, normalize_advantage, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, target_kl, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     82\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[ActorCriticPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    108\u001b[0m ):\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    110\u001b[0m         policy,\n\u001b[0;32m    111\u001b[0m         env,\n\u001b[0;32m    112\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m    113\u001b[0m         n_steps\u001b[38;5;241m=\u001b[39mn_steps,\n\u001b[0;32m    114\u001b[0m         gamma\u001b[38;5;241m=\u001b[39mgamma,\n\u001b[0;32m    115\u001b[0m         gae_lambda\u001b[38;5;241m=\u001b[39mgae_lambda,\n\u001b[0;32m    116\u001b[0m         ent_coef\u001b[38;5;241m=\u001b[39ment_coef,\n\u001b[0;32m    117\u001b[0m         vf_coef\u001b[38;5;241m=\u001b[39mvf_coef,\n\u001b[0;32m    118\u001b[0m         max_grad_norm\u001b[38;5;241m=\u001b[39mmax_grad_norm,\n\u001b[0;32m    119\u001b[0m         use_sde\u001b[38;5;241m=\u001b[39muse_sde,\n\u001b[0;32m    120\u001b[0m         sde_sample_freq\u001b[38;5;241m=\u001b[39msde_sample_freq,\n\u001b[0;32m    121\u001b[0m         rollout_buffer_class\u001b[38;5;241m=\u001b[39mrollout_buffer_class,\n\u001b[0;32m    122\u001b[0m         rollout_buffer_kwargs\u001b[38;5;241m=\u001b[39mrollout_buffer_kwargs,\n\u001b[0;32m    123\u001b[0m         stats_window_size\u001b[38;5;241m=\u001b[39mstats_window_size,\n\u001b[0;32m    124\u001b[0m         tensorboard_log\u001b[38;5;241m=\u001b[39mtensorboard_log,\n\u001b[0;32m    125\u001b[0m         policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs,\n\u001b[0;32m    126\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m    127\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m    128\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m    129\u001b[0m         _init_setup_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    130\u001b[0m         supported_action_spaces\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    131\u001b[0m             spaces\u001b[38;5;241m.\u001b[39mBox,\n\u001b[0;32m    132\u001b[0m             spaces\u001b[38;5;241m.\u001b[39mDiscrete,\n\u001b[0;32m    133\u001b[0m             spaces\u001b[38;5;241m.\u001b[39mMultiDiscrete,\n\u001b[0;32m    134\u001b[0m             spaces\u001b[38;5;241m.\u001b[39mMultiBinary,\n\u001b[0;32m    135\u001b[0m         ),\n\u001b[0;32m    136\u001b[0m     )\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;66;03m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;66;03m# because of the advantage normalization\u001b[39;00m\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m normalize_advantage:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:86\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, n_steps, gamma, gae_lambda, ent_coef, vf_coef, max_grad_norm, use_sde, sde_sample_freq, rollout_buffer_class, rollout_buffer_kwargs, stats_window_size, tensorboard_log, monitor_wrapper, policy_kwargs, verbose, seed, device, _init_setup_model, supported_action_spaces)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     63\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtype\u001b[39m[ActorCriticPolicy]],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     84\u001b[0m     supported_action_spaces: Optional[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mtype\u001b[39m[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     85\u001b[0m ):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     87\u001b[0m         policy\u001b[38;5;241m=\u001b[39mpolicy,\n\u001b[0;32m     88\u001b[0m         env\u001b[38;5;241m=\u001b[39menv,\n\u001b[0;32m     89\u001b[0m         learning_rate\u001b[38;5;241m=\u001b[39mlearning_rate,\n\u001b[0;32m     90\u001b[0m         policy_kwargs\u001b[38;5;241m=\u001b[39mpolicy_kwargs,\n\u001b[0;32m     91\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m     92\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[0;32m     93\u001b[0m         use_sde\u001b[38;5;241m=\u001b[39muse_sde,\n\u001b[0;32m     94\u001b[0m         sde_sample_freq\u001b[38;5;241m=\u001b[39msde_sample_freq,\n\u001b[0;32m     95\u001b[0m         support_multi_env\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     96\u001b[0m         monitor_wrapper\u001b[38;5;241m=\u001b[39mmonitor_wrapper,\n\u001b[0;32m     97\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m     98\u001b[0m         stats_window_size\u001b[38;5;241m=\u001b[39mstats_window_size,\n\u001b[0;32m     99\u001b[0m         tensorboard_log\u001b[38;5;241m=\u001b[39mtensorboard_log,\n\u001b[0;32m    100\u001b[0m         supported_action_spaces\u001b[38;5;241m=\u001b[39msupported_action_spaces,\n\u001b[0;32m    101\u001b[0m     )\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps \u001b[38;5;241m=\u001b[39m n_steps\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m=\u001b[39m gamma\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\stable_baselines3\\common\\base_class.py:181\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[1;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vec_normalize_env \u001b[38;5;241m=\u001b[39m unwrap_vec_normalize(env)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supported_action_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 181\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, supported_action_spaces), (\n\u001b[0;32m    182\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe algorithm only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_action_spaces\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as action spaces \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    183\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was provided\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    184\u001b[0m     )\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support_multi_env \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: the model does not support multiple envs; it requires \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma single vectorized environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m     )\n",
      "\u001b[1;31mAssertionError\u001b[0m: The algorithm only supports (<class 'gymnasium.spaces.box.Box'>, <class 'gymnasium.spaces.discrete.Discrete'>, <class 'gymnasium.spaces.multi_discrete.MultiDiscrete'>, <class 'gymnasium.spaces.multi_binary.MultiBinary'>) as action spaces but MultiDiscrete([3 3 3 3]) was provided"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "\n",
    "# ‚úÖ Load Data & Train XGBoost\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\"]\n",
    "data_handler = StockDataHandler(tickers, api_key=\"YOUR_API_KEY\", outputsize=\"full\")\n",
    "data_handler.fetch_data()\n",
    "df = data_handler.get_data()\n",
    "\n",
    "df.columns = ['_'.join(col) if isinstance(col, tuple) else col for col in df.columns]\n",
    "print(f\"üìä Updated DataFrame Columns: {df.columns}\")\n",
    "\n",
    "\n",
    "xgb_trader = XGBoostTrader(df)\n",
    "xgb_trader.train_models()\n",
    "\n",
    "# ‚úÖ Print the actual column names\n",
    "print(f\"üìä DataFrame Columns Before Prediction: {df.columns}\")\n",
    "\n",
    "# ‚úÖ Train PPO\n",
    "#xgb_predictions = {ticker: xgb_trader.predict(df[f\"{ticker}_close\"]) for ticker in tickers}\n",
    "xgb_predictions = {}\n",
    "for ticker in tickers:\n",
    "    column_name = f\"{ticker}_close\"\n",
    "    \n",
    "    # ‚úÖ Debug check\n",
    "    if column_name not in df.columns:\n",
    "        print(f\"‚ùå Warning: {column_name} not found in DataFrame. Skipping {ticker}.\")\n",
    "        continue\n",
    "\n",
    "    # ‚úÖ Ensure we extract a DataFrame (not a Series)\n",
    "    stock_data = df[[column_name]]  # Keep it as DataFrame\n",
    "\n",
    "    for ticker, prediction in xgb_predictions.items():\n",
    "        print(f\"üîç {ticker} prediction type: {type(prediction)}, shape: {np.array(prediction).shape}\")\n",
    "\n",
    "    xgb_predictions = {ticker: float(np.array(prediction).flatten()[0]) for ticker, prediction in xgb_predictions.items()}\n",
    "\n",
    "\n",
    "env = DummyVecEnv([lambda: StockTradingEnv(tickers, df, xgb_predictions)])\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=20000)\n",
    "model.save(\"stock_trading_ppo_xgb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679df0a-367e-4bfe-91bb-7d6d872e7b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
